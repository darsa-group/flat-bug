{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","cell_execution_strategy":"setup","authorship_tag":"ABX9TyM2854iTIDMhFboGfyPR/kX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["#@title Flat-bug demo\n","\n","#@markdown First make sure that you are using a GPU instance by click on `Runtime` > `Change runtime type` > `T4 GPU` or any other instance with `GPU` must be selected.\n","\n","#@markdown Then press the grey arrow on the left of this cell to start the installation.\n","\n","#@markdown Once the installation is complete (it should take less than a minute), the app should start. You can also click on the link to open it in a new tab.\n","\n","# flat-bug install\n","\n","# Install dependencies\n","!pip install gradio rawpy\n","\n","# clone the repo\n","\n","# Save the private RSA key to a file\n","private_key = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\n","b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAACFwAAAAdzc2gtcn\n","NhAAAAAwEAAQAAAgEAwphOgMSuMkRvEJeqL6uHsHYrOMC1V7GjJq1lEbRp+hPuyalsYhRm\n","r0yIk5AL+ViBixl3crMvM11nFv8wN3oboINx2vLMZe8CFkLKWyfDl3I88LLPnoGuAoJZnw\n","e+mgBsvbtJfRPePjbnJc7C+aEQM3v8IBAFLD9135LZR+878UeiB0Sw3aCxTuuFxkoCuTFm\n","2CiGrtaRiaqix28TCzLQj9EYE369BfADGYySuFqwLCzZl6lZA9c6NY7U4cp3XCOQNz/1Oi\n","1ljK2jVx6fR4yTezSpKtIkKh3NjZqEKpMubGVVoW5gGOkgaZZtaEOjH5k95iNnCZ7zHuDW\n","0XoEHmpDCskMEnAZjhvHyrZveJ4OufYq7ZTrBDqgDZd6i3kkq751mshNNrV2UV6YE8KQoi\n","sWeYJrKymFj67BR+gG7h+6RdVrvCc+iX0XJbTkXJpO7eqpNvrYO9N5zLX3SCjieYBRu8VF\n","qxGCvcAnUb4sfZIGWug4Qxcz4OuRSz5Ve6NnAz3a4sYDxiDOqN+I3f3LI7QIQqm8IVGDv0\n","9qo5aMt37Ey3T+Oicq3UcunPq3F9RR5bhyhrHDlR0PH70piqUWT6sUicF/dh8xHG90mJE7\n","uZOgCYWc5F7z3XFnTqAJqcC1lf+9ygkYXgzCH9PDHJtXlAo2KFmfGpnlpEvatEKYX+7unT\n","kAAAdIE6UkzBOlJMwAAAAHc3NoLXJzYQAAAgEAwphOgMSuMkRvEJeqL6uHsHYrOMC1V7Gj\n","Jq1lEbRp+hPuyalsYhRmr0yIk5AL+ViBixl3crMvM11nFv8wN3oboINx2vLMZe8CFkLKWy\n","fDl3I88LLPnoGuAoJZnwe+mgBsvbtJfRPePjbnJc7C+aEQM3v8IBAFLD9135LZR+878Uei\n","B0Sw3aCxTuuFxkoCuTFm2CiGrtaRiaqix28TCzLQj9EYE369BfADGYySuFqwLCzZl6lZA9\n","c6NY7U4cp3XCOQNz/1Oi1ljK2jVx6fR4yTezSpKtIkKh3NjZqEKpMubGVVoW5gGOkgaZZt\n","aEOjH5k95iNnCZ7zHuDW0XoEHmpDCskMEnAZjhvHyrZveJ4OufYq7ZTrBDqgDZd6i3kkq7\n","51mshNNrV2UV6YE8KQoisWeYJrKymFj67BR+gG7h+6RdVrvCc+iX0XJbTkXJpO7eqpNvrY\n","O9N5zLX3SCjieYBRu8VFqxGCvcAnUb4sfZIGWug4Qxcz4OuRSz5Ve6NnAz3a4sYDxiDOqN\n","+I3f3LI7QIQqm8IVGDv09qo5aMt37Ey3T+Oicq3UcunPq3F9RR5bhyhrHDlR0PH70piqUW\n","T6sUicF/dh8xHG90mJE7uZOgCYWc5F7z3XFnTqAJqcC1lf+9ygkYXgzCH9PDHJtXlAo2KF\n","mfGpnlpEvatEKYX+7unTkAAAADAQABAAAB/3LHY4aQfC8qLlibHMcBZgevq87N3Cjdnl4x\n","6GuI/vmCyFYqmMNBRVAg1G41iNqKWd6yJsKA7lZdwXDPFKGkZKdI4N9EV0vIrnJy8ujRi4\n","zI1SkkT1IvK3RPbo1fBA3SMlG3JqGgFnab67thOaAEYIn9l7lRubtfsycsdvz3H2Qx3GBt\n","I+WV4v+p7D4JaZHSkdbuEIMQDMgm3dzEp3bzghFSQ+E74EKgTzPCtsgGteNYkP/j451gVf\n","VBSk/kHIM8dtQf5YVrQXq48J9ycIDDajpB1YZsbOhqq9PaUBrMtZU6MEgH0qbe2z9sexwE\n","yTLaMKiOOThziPOtqwfj8IoAI4oxNymX1BXjGCet4hv32Lp1bgkhlyE1rkWXHXhuAeKC+c\n","K5HxCIijlwvEDWf3NztgN2D744Bqt9cCo15T4fSRCuDmVpqwVuP16cll7P8aoz7Lr5QrA2\n","SV04l/ptVnc5w4byuY8/eG6sY0ePkD54P77cvtecWU7Y9jHM2RCxBJKBMD2erP1SexTkEn\n","aMG+or8sjjkBc/+ZGyltKsumVQ7XzkBm6lU1tBzXxKposDqBog8mDLNhuYxYvTNmlBZ5cS\n","rD3R2A6r01N3H9Cnr1I1bK8lke37V/xmEW+NoH9grHy0GjA8TaJWIa6BmMKo0R/W5KsMQO\n","nlbF17rMHgShgGXfEAAAEAbeaPk/fD0KqUCasUxJs/idC9SX5vio2pe7qEsbPgBwKUn+8j\n","fHhrkVWWcVdvivA0KxKZPPFcay2GhlVQ52KsrLEfACzUP9FXKiSXoczJ3LmLBd2t6h8Mte\n","yWrSck8xxcxa+bdQnjjLT6PBId5hEpaDT7olz2fPAI7MQLuYSAnpoKyVK8yuhg6rGeibwT\n","aS02PL14gsLtPC/IDbFqYC5co5tj5gH9a4w7NwBloQCYCrBL8t5lJhFmXpQ7HWxfxOajGa\n","ONR107h8qiQOm6tPPwweLDWchI8L7BR6USs8zIXuHDCeJEUtdz6mMXefNVFGZCZFJoUtd5\n","svHOSywj1xrvuwAAAQEA7dA1+t4SP8ZUuTNFe45mItLkZjSvA9aLBoPbvBVlMfRuOEdyQy\n","Nn84p/MmHktVjam2kNPBBtdW1Kft8J8SD6isgMeuIv2Az65XHU402N4Y3xsaADHwmQs0Bi\n","fZYESeM68EB/D6aoPIKWvDeBr+Wdnmwngzq7NCB9box6IrEI7HeOdKNDL95KRP+6NFjlDJ\n","OFbvtmFN5xxd4vHPUdIBQiV5O89PU/nidK2nhy7+oZX3bBnyGjkxZRUWpAsXzdzmSZi8Qm\n","j9kVIxlr+SdEBVrtIBP4c2bvrxj60BaEu9DTmAor2KMIp2gVGfvXWVum2TDf9YYLMuPEtL\n","oVPmVWpiwd1QAAAQEA0Xn8/pJ+CXnCqhj0qIKJj0LadNswQUfYkgDBdr1dZ3F0R1JrLXwC\n","4cv7AjGkHU6iAE/B5xFLu7Af6eay/Im32oogd7IT96gsvpETwKUEPKnLZFxlrbMSdhIb4r\n","XAjIGSRi6x/LkGAxnKWmHRcWXiZck3y5imOzjJIRc4iQv+hKeTXxTh4pQiosB8l0+N3D6P\n","uwLijDdpN+cfQmgDaFBbb55/cws6V2Gcj+h1/X9WCTfxl5EoHaxFx7S3W1QyUuq+NZY4pZ\n","UQ+jcYn7WPKqy1tMk3RqMF7ks3ohGTNcTG2fyzp/7hBs79xt6NuWBRzPbb/NA5iFfk1cm/\n","/Vawl6kf1QAAABN1bmlcYXU3NjEzNjdARDU2MzMwAQ==\n","-----END OPENSSH PRIVATE KEY-----\n","\"\"\"\n","\n","# Save the key into a file with restricted permissions\n","!mkdir -p /root/.ssh\n","with open('/root/.ssh/id_rsa', 'w') as key_file:\n","    key_file.write(private_key)\n","\n","# Change file permissions to read-only\n","!chmod 600 /root/.ssh/id_rsa\n","\n","# Create the SSH configuration file\n","ssh_config = \"\"\"\n","Host github-flat-bug\n","    HostName github.com\n","    AddKeysToAgent yes\n","    PreferredAuthentications publickey\n","    IdentityFile /root/.ssh/id_rsa\n","\"\"\"\n","\n","# Write the SSH configuration to the appropriate location\n","with open('/root/.ssh/config', 'w') as config_file:\n","    config_file.write(ssh_config)\n","\n","# Set the correct permissions for the SSH configuration file\n","!chmod 600 /root/.ssh/config\n","\n","! ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts\n","! chmod go-rwx /root/.ssh/id_rsa\n","\n","# the github token is temporary\n","# !git clone https://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@github.com/darsa-group/flat-bug\n","# !git clone https://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@github.com/darsa-group/flat-bug --branch develop --single-branch flat-bug/\n","!git clone git@github.com:darsa-group/flat-bug.git --branch develop --single-branch flat-bug/\n","\n","# Bug fix: flat-bug requires python >= 3.11 and colab is currently running with Python = 3.10\n","# This was easier to change flat-bug change colab.\n","\n","import re\n","\n","def find_and_replace_in_file(file_path, search_pattern, replacement_text):\n","    \"\"\"\n","    Find and replace text in a Python (.py) file using regex.\n","\n","    :param file_path: Path to the .py file\n","    :param search_pattern: Regex pattern to search for\n","    :param replacement_text: Replacement text\n","    \"\"\"\n","    try:\n","        # Read the file content\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            content = file.read()\n","\n","        # Replace using regex\n","        updated_content = re.sub(search_pattern, replacement_text, content)\n","\n","        # Write the updated content back to the file\n","        with open(file_path, 'w', encoding='utf-8') as file:\n","            file.write(updated_content)\n","\n","        print(f\"Replaced text in '{file_path}' successfully.\")\n","    except FileNotFoundError:\n","        print(f\"File '{file_path}' not found.\")\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","\n","find_and_replace_in_file('flat-bug/pyproject.toml', r'requires-python = \">=3.11\"', 'requires-python = \">=3.10\"')\n","self_replace = \"from typing_extensions import Self\"\n","find_and_replace_in_file('flat-bug/src/flat_bug/predictor.py',\n","                         r'from typing import Any, List, Optional, Self, Tuple, Union',\n","                         f'from typing import Any, List, Optional, Tuple, Union\\n{self_replace}')\n","find_and_replace_in_file('flat-bug/src/flat_bug/augmentations.py',\n","                         r'from typing import Dict, List, Optional, Self, Tuple, Union',\n","                         f'from typing import Dict, List, Optional, Tuple, Union\\n{self_replace}')\n","find_and_replace_in_file('flat-bug/src/flat_bug/trainers.py',\n","                         r'from typing import Any, Dict, List, Optional, Self, Tuple, Union',\n","                         f'from typing import Any, Dict, List, Optional, Tuple, Union\\n{self_replace}')\n","find_and_replace_in_file('flat-bug/src/flat_bug/datasets.py',\n","                         r'from typing import Dict, List, Optional, Self, Tuple, Union',\n","                         f'from typing import Dict, List, Optional, Tuple, Union\\n{self_replace}')\n","\n","# install the package\n","!pip install -e flat-bug\n","\n","# fix the package path to sys.path\n","import sys\n","sys.path.append(\"/content/flat-bug/src\")\n","\n","# Localization implementation\n","\n","import os, glob, json, io, zipfile, base64, uuid, re, tempfile\n","\n","from urllib.request import urlretrieve\n","from copy import deepcopy\n","from typing import List, Tuple, Union, Optional\n","from tqdm import tqdm\n","\n","import numpy as np\n","import torch\n","\n","import rawpy\n","from PIL import Image\n","\n","from flat_bug.predictor import Predictor, TensorPredictions\n","\n","# Input parsing\n","IMG_REGEX = re.compile(r'\\.(jp[e]{0,1}g|png|dng)$', re.IGNORECASE)\n","\n","def is_image(file_path):\n","    return bool(re.search(IMG_REGEX, file_path)) and os.path.isfile(file_path)\n","\n","def is_txt(file_path):\n","    return file_path.endswith('.txt') and os.path.isfile(file_path)\n","\n","def is_dir(file_path):\n","    return os.path.isdir(file_path)\n","\n","def is_glob(file_path):\n","    return not (is_image(file_path) or is_dir(file_path))\n","\n","def type_of_path(file_path):\n","    if is_image(file_path):\n","        return 'image'\n","    elif is_txt(file_path):\n","        return 'txt'\n","    elif is_dir(file_path):\n","        return 'dir'\n","    elif is_glob(file_path):\n","        return 'glob'\n","    else:\n","        return 'unknown'\n","\n","def get_images(input_path_dir_globs : Union[str, List[str]]) -> List[str]:\n","    if isinstance(input_path_dir_globs, str):\n","        input_path_dir_globs = [input_path_dir_globs]\n","    images = []\n","    for path in input_path_dir_globs:\n","        match type_of_path(path):\n","            case 'image':\n","                images.append(path)\n","            case 'txt':\n","                with open(path, 'r') as f:\n","                    paths = [path.strip() for path in f.readlines() if len(path.strip()) > 0]\n","                images.extend(get_images(paths))\n","            case 'dir':\n","                images.extend(glob.glob(os.path.join(path, '*')))\n","            case 'glob':\n","                images.extend(glob.glob(path))\n","            case _:\n","                raise ValueError(f\"Unknown path type: {path}\")\n","    if len(images) == 0:\n","        raise ValueError(\"No images found\")\n","    return images\n","\n","# Image processing\n","class ImageEncoder(json.JSONEncoder):\n","    def default(self, o):\n","        if isinstance(o, Base64Image):\n","            return str(o)\n","        else:\n","            return super().default(o)\n","\n","class Base64Image:\n","    def __init__(self, path : str):\n","        self.path = path\n","        self.bytes = base64.b64encode(open(path, \"rb\").read())\n","        self.str = self.bytes.decode(\"ascii\")\n","\n","    def __str__(self):\n","        return self.str\n","\n","    def __bytes__(self):\n","        return self.bytes\n","\n","    def __repr__(self) -> str:\n","        return f\"Base64Image({self.path})\"\n","\n","def parse_image(images : Optional[Union[np.ndarray, bytes, str, Union[List[Union[np.ndarray, bytes, str]], Tuple[Union[np.ndarray, bytes, str]]]]], device : Union[torch.device, str]=\"cpu\"):\n","    # Cases:\n","    # List: Recursively parse each image\n","    if isinstance(images, (list, tuple)):\n","        return [parse_image(image, device) for image in images]\n","    # String: Open the image with PIL\n","    elif isinstance(images, str):\n","        if re.search(re.compile(\"\\.dng$\", re.IGNORECASE), images):\n","            with rawpy.imread(images) as raw:\n","                images = raw.postprocess()\n","                images = Image.fromarray(images)\n","        else:\n","            images = Image.open(images)\n","    # Bytes: Open the image with PIL using a BytesIO\n","    elif isinstance(images, bytes):\n","        images = Image.open(io.BytesIO(images))\n","    # Numpy array: Do nothing\n","    elif isinstance(images, np.ndarray):\n","        pass\n","    # Other: Raise an error\n","    else:\n","        raise ValueError(f\"Expected image(s) to be a np.ndarray, string or bytes, or list of these, but got {type(images)}\")\n","\n","    # Convert the image to a numpy array\n","    image = np.array(images)\n","\n","    # Convert the image to a torch tensor and change from HWC to CHW\n","    return torch.from_numpy(image).permute(2, 0, 1).to(device)\n","\n","# General file handling\n","def generate_uuid() -> str:\n","    return str(uuid.uuid4())[::3]\n","\n","def save_file(content : str, name : str, dir : str, ext : str, identifier : Optional[str]=None, dtype : str=\"text\") -> str:\n","    # Is the data raw bytes or text?\n","    if \"text\" in dtype:\n","        dtype = \"\"\n","    elif \"byte\" in dtype:\n","        dtype = \"b\"\n","    # If the UUID is not specified, generate a new one\n","    if identifier is None:\n","        identifier = generate_uuid()\n","    # Construct the path\n","    path = f\"{dir}/{identifier}_{name}.{ext}\"\n","    # Dump the content to the file\n","    with open(path, f\"w{dtype}\") as f:\n","        f.write(content)\n","    # Return the path\n","    return path\n","\n","def zip_files(files : List[str], name : str, dir : str, identifier : Optional[str]=None) -> str:\n","    # If the UUID is not specified, generate a new one\n","    if identifier is None:\n","        identifier = generate_uuid()\n","    # Construct the path\n","    path = f\"{dir}/{identifier}_{name}.zip\"\n","    # Open the zip file\n","    with zipfile.ZipFile(path, \"w\") as z:\n","        # Add all the files\n","        for file in files:\n","            if isinstance(file, Base64Image):\n","                z.write(file.path)\n","            else:\n","                z.write(file)\n","    # Return the path\n","    return path\n","\n","# Model definition\n","class Localizer(Predictor):\n","    def predict(self, images : Optional[Union[np.ndarray, bytes, str, Union[List[Union[np.ndarray, bytes, str]], Tuple[Union[np.ndarray, bytes, str]]]]], do_plot : bool | List[bool]=False, include_crops : bool=False, outdir : str=\"output\") -> dict:\n","        # Initialize the data\n","        data = {\n","            \"uuids\": [],\n","            \"predictions\": [],\n","            \"crops\" : [],\n","            \"visualizations\": []\n","        }\n","\n","        if not isinstance(images, (list, tuple)):\n","            images = [images]\n","        if not isinstance(do_plot, list):\n","            if isinstance(do_plot, tuple):\n","                do_plot = list(do_plot)\n","            else:\n","                do_plot = [do_plot]\n","            if len(do_plot) == 1 and len(images) > 1:\n","                do_plot = do_plot * len(images)\n","        if not all([isinstance(plot, bool) for plot in do_plot]):\n","            raise ValueError(f\"Expected do_plot to be a boolean or list of booleans, but got {do_plot}\")\n","\n","        for i, image in enumerate(tqdm(images, desc=\"Localizing insects\", unit=\"image\", leave=True)):\n","            if isinstance(image, str):\n","                image_identifier = os.path.splitext(os.path.basename(image))[0]\n","            else:\n","                image_identifier = \"XPRIZE_BiodivX\"\n","            # Fetch the image\n","            image = parse_image(image, self._device)\n","\n","            # Generate uuid for the image\n","            identifier = generate_uuid()\n","\n","            # Create the output directory\n","            this_outdir = os.path.join(outdir, identifier)\n","            if not os.path.exists(this_outdir):\n","                os.makedirs(this_outdir)\n","\n","            # Run the model\n","            predictions : TensorPredictions = self.pyramid_predictions(image, \"DUMMY_PATH_STR\", scale_before=1/2)\n","\n","            # Save crops\n","            predictions.save_crops(outdir=this_outdir, basename=image_identifier, mask=True, identifier=identifier)\n","            crops = [Base64Image(crop) if include_crops else crop for crop in glob.glob(os.path.join(this_outdir, f\"crop*{identifier}.png\"))]\n","\n","            # Plot the image if requested\n","            if do_plot[i]:\n","                visualization_dir = os.path.join(os.path.dirname(this_outdir), \"visualization\")\n","                if not os.path.exists(visualization_dir):\n","                    os.makedirs(visualization_dir)\n","                predict_image = os.path.join(visualization_dir, f'{identifier}_visualization.jpg')\n","                predictions.plot(outpath=predict_image, scale=1/2)\n","                # base64_image = Base64Image(predict_image)\n","            else:\n","                # base64_image = None\n","                predict_image = None\n","\n","            # Append the data\n","            data[\"uuids\"].append(identifier)\n","            data[\"visualizations\"].append(predict_image)\n","            data[\"crops\"].append(crops)\n","            data[\"predictions\"].append(predictions.json_data)\n","\n","        # Return the predictions as JSON\n","        return data\n","\n","def get_defaults():\n","    # Define the model parameters\n","    remote_dir = \"https://anon.erda.au.dk/share_redirect/aRbj0NCBkf\"\n","    config_file = \"config.yml\"\n","    remote_config = \"fb_xprize_large.yml\"\n","    weights = \"weights.pt\"\n","    remote_weights = \"fb_xprize_large.pt\"\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    dtype = torch.float16\n","\n","    # Checks\n","    if not os.path.exists(config_file):\n","        urlretrieve(f\"{remote_dir}/{remote_config}\", config_file)\n","    if not os.path.exists(config_file):\n","        raise ValueError(f\"Could not find {config_file} file even after downloading?\")\n","    if not os.path.exists(weights):\n","        urlretrieve(f\"{remote_dir}/{remote_weights}\", weights)\n","    if not os.path.exists(weights):\n","        raise ValueError(f\"Could not find {weights} file even after downloading?\")\n","\n","    return config_file, weights, device, dtype\n","\n","def main(args : dict):\n","    # Get the defaults\n","    config_file, weights, device, dtype = get_defaults()\n","\n","    # Update the parameters\n","    image_paths = get_images(args[\"input\"])\n","\n","    if \"config\" in args and args[\"config\"] is not None:\n","        config_file = args[\"config\"]\n","\n","    if \"weights\" in args and args[\"weights\"] is not None:\n","        weights = args[\"weights\"]\n","\n","    if \"device\" in args and args[\"device\"] is not None:\n","        device = torch.device(args[\"device\"])\n","\n","    if \"dtype\" in args and args[\"dtype\"] is not None:\n","        dtype = getattr(torch, args[\"dtype\"])\n","\n","    if not \"output\" in args or args[\"output\"] is None:\n","        outdir = tempfile.mkdtemp()\n","    else:\n","        outdir = args[\"output\"]\n","        if not os.path.exists(outdir):\n","            os.makedirs(outdir)\n","\n","    # Create the model\n","    model = Localizer(model=weights, cfg=config_file, device=device, dtype=dtype)\n","    model.set_hyperparameters(SCORE_THRESHOLD=0.25, EDGE_CASE_MARGIN=32, MIN_MAX_OBJ_SIZE=(16, 768), TIME=False)\n","\n","    # Run the model\n","    output = model.predict(image_paths, do_plot=args.get(\"plot\", False), include_crops=False, outdir=outdir)\n","    output_json = save_file(json.dumps(output, cls=ImageEncoder), name=\"instances\", dir=outdir, ext=\"json\", dtype=\"text\")\n","\n","    # Print the result path\n","    print(f\"Results have saved to {os.path.abspath(outdir)}\")\n","\n","    return output\n","\n","\n","#-------------------------------------------------------------------------------\n","# Gradio app.\n","\n","\n","import os, json\n","\n","from typing import List, Tuple, Optional, Union\n","\n","import numpy as np\n","import gradio as gr\n","\n","# from localize import Localizer, ImageEncoder, save_file, zip_files, get_defaults, Base64Image\n","\n","# def html_base64_img(b64: Union[str, bytes]) -> str:\n","#     if isinstance(b64, bytes):\n","#         b64 = b64.decode(\"ascii\")\n","#     return f'<img src=\"data:image/jpeg;base64,{b64}\"/>'\n","\n","def combine(*args):\n","    out = []\n","    [out.extend(a) if isinstance(a, list) else out.append(a) for a in args if a is not None]\n","    return out\n","\n","# Define the postprocessing function\n","def postprocess(out : dict) -> List[Tuple[str, str]]:\n","    \"\"\"\n","    Postprocess the output of the model.\n","\n","    Arguments:\n","        out: The output of the model.\n","\n","    Returns: A list of tuples with the JSON string and paths to saved images.\n","    \"\"\"\n","    n = len(out[\"predictions\"])\n","    json_files = [save_file(json.dumps([out[k][i] for k in out], cls=ImageEncoder), name=\"instances\", dir=\"output\", ext=\"json\", identifier=out[\"uuids\"][i], dtype=\"text\") for i in range(n)]\n","    return (\n","        json_files,\n","        [zip_files(combine(out[\"crops\"][i], out[\"visualizations\"][i], json_files[i]), name=\"combined\", dir=\"output\", identifier=out[\"uuids\"][i]) for i in range(n)],\n","        [out[\"visualizations\"][i].path if isinstance(out[\"visualizations\"][i], Base64Image) else out[\"visualizations\"][i] for i in range(n)],\n","        [[crop.path if isinstance(crop, Base64Image) else crop for crop in out[\"crops\"][i]] for i in range(n)]\n","    )\n","\n","with gr.Blocks() as demo:\n","    config_file, weights, device, dtype = get_defaults()\n","\n","    # Create a model loader\n","    def get_model():\n","        return Localizer(model=weights, cfg=config_file, device=device, dtype=dtype)\n","\n","    # Load the model in the app state\n","    model = gr.State(get_model)\n","\n","    # Define the localization function\n","    def localize(images : Optional[Union[np.ndarray, bytes, str, Union[List[Union[np.ndarray, bytes, str]], Tuple[Union[np.ndarray, bytes, str]]]]],\n","                #  do_plot : bool=False) -> Tuple[List[str], List[str]]:\n","                 ) -> Tuple[List[str], List[str]]:\n","        if not os.path.exists(\"output\"):\n","            os.makedirs(\"output\")\n","        # predictions = model.value().predict(images, do_plot=do_plot, include_crops=True, outdir=\"output\")\n","        predictions = model.value().predict(images, do_plot=True, include_crops=True, outdir=\"output\")\n","        return postprocess(predictions)\n","\n","\n","    # Define the input-output format\n","    file_input = gr.Image(value=\"example_image1.jpg\", label=\"Input image\")\n","    # checkbox = gr.Checkbox(label=\"Return annotated image\")\n","    output_json = gr.File(label=\"Output JSON\")\n","    output_zip = gr.File(label=\"Output ZIP\")\n","    output_image = gr.Image(label=\"Annotated Image\", format=\"jpg\")\n","    output_crops = gr.Gallery(label=\"Cropped insects\", format=\"png\")\n","    # test_output = gr.HTML(label=\"test output\")\n","\n","    gr.Interface(\n","        fn=localize,\n","        inputs=[file_input],\n","        outputs=[output_json, output_zip, output_image, output_crops],\n","        title=\"Perform localization on a single image\",\n","        # description=\"This model localizes bugs in images. Upload an image and it will return the localization as a JSON file and optionally an annotated image.\",\n","        description=\"This model localizes bugs in images. Upload an image and it will return the localization as a JSON file and an annotated image.\",\n","        batch=True\n","    )\n","\n","from IPython.display import clear_output\n","clear_output(wait=True)\n","demo.launch(inbrowser=True)\n"],"metadata":{"id":"vBuB9qVqqWX7","cellView":"form"},"execution_count":null,"outputs":[]}]}